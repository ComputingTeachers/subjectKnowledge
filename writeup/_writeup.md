# Developing an effective tool to enable trainee teachers to perform an accurate gap analysis of their existing skill-set

Abstract
--------

As a Teacher Educator, I want to improve trainee teachers pedagogical development. Trainee teachers are required to show evidence of the their subject knowledge development to meet the UK teachers' standards.

Explain Why this come to attention


Overview
--------

Background as a secondary teacher, senior software engineer, teacher educator






### Action Research Question
Can trainee teachers accurately self-evaluate their subject knowledge and use this to guide their subject knowledge development?

* An appropriate range of relevant issues identified and distinctive approach taken in dealing with them.

??? aims/ objectives / intervention?

### Context for the research
* Trainee Computing teachers need to accurately perform a gap analysis of their skill-set to self-guide their subject knowledge development over the duration of their one-year PGCE course. The purpose of the PGCE is to help trainees engage in continuous critical reflection.
* Mentors and trainees have expressed that; The existing subject knowledge audit is ineffective as it allow for personal interpretation of ability and typically measure the 'confidence' of the trainee.
* Intervention: Revise the computing subject knowledge audit
    * Remove the 'personal interpretation' from judgement of level of skill
* Identify how the trainee’s confidence is impacted by this new tool.
    * Will overly confident trainees be surprised or demoralised by the limits of their subject knowledge?



Literature Review
-----------------

Developing teachers subject knowledge is a core component of Initial Teacher Training (Department for Education, “Initial Teacher Training (ITT): Core Content Framework” and “Teachers’ Standards”).
In 2016 Sentance and Csizmadia surveyed 300 Computing teachers in the UK (Sentance and Csizmadia). The biggest concern computing teachers had was "sufficient subject knowledge". 2016 was two years after the new computing curriculum for schools was introduced (2014). I suspect that in 2022 this is likely to have changed.


### Enhancing Teaching, Assessing and Supporting HE (ETAS) - Question

I wrote a short piece earlier this year raising question the issues about supporting teachers subject knowledge development in computing. A few important excerpts are listed below:

Students are required to self assess their skills and identify their subject knowledge gaps (Rhoades 2014). Rhoades states "any overestimation or even underestimation of your knowledge will be counter productive". Trainee's self assessment of subject knowledge is varied and inaccurate as trainees have no benchmark or reference point to based their skills assessment upon (Schmid 2021 1.1). Trainees lack the knowledge of the curriculum to judge if their stills are sufficient. (Jones et al., 2019) cited McNamara (1991) in stating; a teachers' restricted subject knowledge affects the quality of teaching and causes serious deficiencies in student learning, this deficiency is not immediately identifiable. (D2 V pedagogical research)

> Existing questionnaires have been criticized regarding the fuzzy, technology-unspecific, and content-agnostic wording of questionnaire items, which ask participants to rate the “appropriateness” of their competencies
(Schmid, Brianza and Petko, 2021)

Ultimately assessing subject knowledge for trainee teachers is a secondary concern. What matters is that they can deliver good lessons (V4 wider context). Subject knowledge could ultimately be assessed through the lesson content that the trainees create and deliver. This approach is confirmed by (Blömeke and Delaney, 2014) who state that we should be moving beyond self-reported subject knowledge audits. (K1 subject material)


### Definition of Computing Subject knowledge and skills

Denning, a professor of Computing working at MIT/Princeton and awarded "SIGCSE Award for Lifetime Service to Computer Science Education" has cautioned that
"Many employers no longer trust transcripts and diplomas.". He advocates that "computing education would benefit from a deep look at competency-based assessment". In his paper "Remaining trouble spots with computational thinking" he comparers "Traditional Computational Thinking" and "New Computational Thinking". Old computational thinking is traditional solving problems practically with developing programs on a computer. New computational thinking involves no use of a computer and thinking about problem solving approaches. New CT was coined by Wing (a professor of computer science at Carnegie Mellon) in 2006. Wing stated that these problem solving skills were not just relevant to computing could be used in other disciplines. 

Nijenhuis-Voogt et al did a qualitative study of 7 computing teachers in the netherlands about their approaches. Half of these teachers were coded as Old CT and the other half New CT. Although Kent is not the same setting, this tracks with my perceptions of what I observe in the attitudes of my school computing mentors in Kent. When I raised this point with my trainees in a seminar the debate seemed fairly balanced on both sides. These indicators combined gives me reasonable confidence in suggesting that there is general split between Old CT and New CT in the profession.

There have been debates between these computational thinking two ethos. Denning warns that new computational thinking has no evidence that indicates that the skills are transferable/useful in other domains. I attempted to find evidence for the impact of New CT in other disciplines. With my limited searching I could find any measurable evidence. I agree with Denning. Unless young people build skills by writing real programs, these softer new problem solving skills without a computer appear to have little meaningful value. New CT skills appear limited in scope in industry and limited scope as transferable skills.

Christian and Griffiths in their book Algorithms to Live by: The Computer Science of Human Decisions 2016, attempts to describe computer science patterns that map onto human behaviour. These are often trivial observations e.g. "The use of caching" by keeping regularly used objects in more accessible locations. A deep knowledge of computing does not seem to offer a meaningful advantage or deeper insight into how people engage with everyday activities.

Kolikant 2010 gives an argument for "make the CS classroom more authentic, more similar to the real work setting of CS practitioners" and "substituting lecture for lab time". Historically was a non-exam assessed practical component for GCSE, but in 2018 Ofqual removed this because of mass nationwide cheating (Ofqual 2018). Trying to add practical components into schools sounds reasonable but Kolikant warns "Many times innovations get 'domesticated', are altered to fit the school grammar in a way that diminishes their change impact".

If New CT has little evidence to support it, then why is it so prevalent? I think this is due to the way computing is assessed in schools. The GCSE is 100% exam based without a computer. Theoretically a student can pass the exam without every touching a computer for the duration of their course. Schools rigorously focus their attention on training students to pass the exam. As GCSE's are the only real metric teachers are held accountable for, I can envisage that this has skewed teacher perception into thinking that New CT has greater weight.

Woodard in his American Affairs opinion piece "Rotten STEM" cautions that STEM is no longer about Science and Maths and is all about providing tech workers for industry. We should be cautions about the requirements of industry contaminating education. Education is border than just developing monetisable skills (Woodard 2019). It may not be wise to map computing education exclusively on to industry requirements.

My preference is that I favour practical application of skill. If young people can create a sound wave with code they will understand how sound is stored and processed by a computer. If young person can send a TCP packet from one computer to another with code then they understand network addresses, ports and sockets. Many of the national curriculums theory requirements can be explained meaningfully though practical application. I expect a computing teachers skill-set to reflect this.



### Other Computing Audits

#### Expert Group: Computer Science Teacher Training (2012)

In 2012 the Department for Education released a document titled “Subject Knowledge Requirements for Entry into Computer Science Teacher Training. Expert Group’s Recommendations”.
> subject knowledge specified below is considered by an expert group ... to be the minimum necessary for trainees to take full advantage of the training offered and to produce teachers capable of teaching a rigorous course in the secondary phase

The content of this document is excellent. It covers many of the core aspects of computing including fetch-execute-cycle, data encoding, network protocols and error correction. Many of these straddle the boundary between GCSE and A-Level. If I was to actually use these criteria as "the minimum necessary" then my course would not run because I would have to reject candidates at interview for subject knowledge.

All the requirements state a trainee should "Explain"; there is no requirement for trainees to "Demonstrate" any of these skills.

#### Leeds Trinity University

* Categorised into 3 broad categories: Knowledge, Skills, and Learning Outcomes
* Items are hard to qualify:
    * "think creatively, innovatively, analytically, logically and critically"
    * use abstraction effectively
    * take a systematic approach to problem solving including the use of decomposition and abstraction, and make use of conventions including pseudo code and flowcharts
* Items are ranked with: (these are not well defined)
    1. I have some knowledge of this
    2. I have secure knowledge of this
    3. I can teach this
    4. I can teach this in several different ways

#### Sommerset Learning Platform

Somerset has a county learning platform that has Computing subject knowledge documents from 2015. The teacher knowledge requirements are a copy of the expert group recommendations with little additional information about how these can be evidenced, achieved or tracked.

#### Survey other subjects audits

These are samples of subject knowledge audits for trainees teachers from Canterbury Christ Church University 2021/2022.

##### Maths

See Appendix XXX

Maths is a very established subject that challenges students problem solving abilities. This has parallels with the algorithmic problem solving in computing.

This is largely the gcse exam-board specification.

##### Music

See Appendix XXX

I selected Music as this subject has a range of demonstrable practical skills rather than desecrate knowledge. I wanted to compare how these practical skills are measured trainees.

Music Tech skills are listed separately. The categories are very broad (e.g Keyboard skills) with a rating 1 to 4. The rating descriptors are significantly lengthy as defined for the institution. Theses are the same descriptors I distilled my computing levels from.


#### Survey of external audits

In 2016 Craig Barton, a maths teacher, demonstrated the value of multiple choice questions where the incorrect answers are deliberately constructed to reveal a particular misconception. The effectiveness was evaluated by a 3 year project by the Education Endowment Foundation. The technique has also been used for testing computing subject knowledge. (“Diagnostic and Summative Assessment of Computing”)
> Gaining an accurate picture of the subject knowledge of your students, and knowing where gaps remain, provides the foundation for success. 

[Subject knowledge certificate](https://teachcomputing.org/cs-accelerator)
> Complete a questionnaire to assess your subject knowledge
[GCSE specifications to Computer Science Accelerator course map (September 2020)](https://static.teachcomputing.org/GCSE_specifications_to_CSA_course_map.pdf)

Subject knowledge certificates are awarded after attending a course module (some online async, online live, or face-to-face) and completing a multiple choice assessment with many of the questions mirrors from eedi.com's diagnostic questions.


### Literature Review Conclusions

lack of practical evidence in subject knowlge audits

What are the research questions ...

..? If you can't write a bubblesort algorithum with code, how can you teach it? .. it's a prerequestit. Other subjects do not seem to identify this practical requirement

A-level by practical
If we take A-Level as a progression model - it is a superset of KS3 and KS4



Research Methodology
--------------------

### The intervention

Rework the PGCE trainee teacher computing subject knowledge audit to include measurable practical implementation of theory skills.


### Aims and objectives
* Aims (statement of intent)
    * Trainees should be able to autonomously perform a subject knowledge gap analysis
    * Trainees should target and evidence subject knowledge development over a 3-month period
* Objectives (actions and measurable outcomes)
    * Ensure that levels of subject knowledge are unambiguous and evidencable
    * Trainee teachers and school mentors to accurately identify their current working level and areas of need
    * Provide a quantitative measure of subject knowledge progress over a 3-month period
    * Trainees should be able to self direct their subject knowledge development

### Intervention
1. Rework the existing 'computing trainee teacher subject knowledge audit'
    * Simplify and remove ambiguity in the criteria for identifying subject knowledge proficiency level
    * Clarify the evidence required to track/justify subject knowledge
    * Survey trainee teachers and school mentors about their perceptions of the new structure for subject knowledge tracking to ascertain effectiveness of the intervention
2. Trainees and mentors’ responses will be captured to identify the effectiveness of this rework
    * Survey trainee’s perceived confidence of their subject knowledge development

### Criteria for evaluation

Key measures indicating success:
1. There is majority preference for the new audit model
    1. From students
    2. From mentors
2. Changes to student confidence levels should remain minimal
    * It should neither strongly inflate or deflate their ego artificially
3. Students feel they can accurately justify their current level of subject knowledge from the audit
4. There is evidence to support that practical computing skills development has taken place
    * This could be evidenced by student portfolio progress when reviewed in December


### Research Design


#### Questionnaires

I will give my trainees two questionnaires (3 months apparat) that survey their experience with the new subject knowledge audit. I will attempt to codify the responses to the open questions. I will use a unipolar likert scale to quantify overarching conclusions for preference for the old/new audit and student self reported confidence.

#### Codification of open question responses

Action Research Education (Mcater 2013) proposes a range of approaches for research techniques in education. I will attempt to perform a thematic analysis by  identifying unexpected data and points of disagreements and codifying these outcomes. I should be cautions about the seduction of dominant discourse. "Modes of discourse become so culturally embedded that they enter into widespread acceptance, and are rarely the subject of question or debate" (Mcateer and British Educational Research Association 107–128 (Chapter 6))

I have a sample size of 7 students and mentors, my study is limited in most of the data quality indicators (Reliability, validity, replicable, objectivity, generalisability). I intend to extract the general themes that arise and discuss them.

Bridges 2007 warns: "At it's best, classroom action research seems to me to represent a reaffirmation of personal integrity, responsibility and authority in an environment that threatens to undermine all of these". Action research's main use is for a practitioner to attempting to realign their thinking.

In Coding Manual For Qualitative Researchers (Saldaña 2016) cites an argument from Strauss's conveying the importance of coding in qualitative research. 
This is counted by an assertion from Packer that on a practical level, coding is impossible to practice. 
The book describes first cycle coding methods and second cycle coding methods for taking open response questions and categorising them. In professional research this codification should be done by someone external to the study or the domain to reduce bias. I will attempt to perform a cut down rendition of these principles.

First cycle, I will identify the main themes and give them a code. Second cycle, I wil attempt to count the number of occurrences of these codes. Because my sample size is so small I will simply this further with reporting the code of themes that have occurred multiple times. I will demonstrate the codes and commentary in my appendix.

This approach is a significantly simplified attempt to interpret my data. This is an area I would like to formalise/develop as I continue my journey with education research.


#### Focus group discussion

Pinar (2011) in his book "What Is Curriculum Theory?" defined the curriculum as "complicated conversations" with practitioners rather than the formulation of objectives evaluated by standardized tests. He posits that the curriculum is largely intertwined with the perceptions of the practitioners that teach it. 

I will record the audio from a focus group conversation between my trainees after 3 months of using the new subject knowledge audit. This open forum will hopefully reveal deeper insights than my questionnaires as this will involve discourse between eh trainee teachers. They will be asked to discuss the same questions given to mentors.

I will attempt to perform an Interpretative phenomenological analysis (IPA) to offer insight into to offer insights into how trainee teachers computing teachers makes sense of a subject knowledge development. This is in the domain of Hermeneutics as the theory and practice of interpretation where the interpretation can be justified.

The small sample size of trainees makes this approach possible.

I will use the same codification process as used with the questionnaires to interpret the focus group discussion.


#### Ethical considerations of research design

This study will alter the way trainees evaluate their subject knowledge. This self identification could impact their personal identity. Given the new audit refers to more practical skills, it is possible that confidence of my trainees could be affected. To mitigate this I will:
* Ensure the audit clearly describes that it "is not used for formal assessment"
* Ensure I collect feedback about the trainees level of confidence - both lichert scale and free-from feedback to detect any issues
* Continually be involve trainees in discussions about subject knowledge development to support them

No changes need to be made to the course in general and no change to assessment or re-validation will be required.

All participants have completed consent forms and are aware that their data is collected anonymously so they will not be identifiable, but their responses will be publicly visible.

Two questionnaires will be given 3 months aspart. To match the trainees responses over the time period, rather than collecting a name I a collect a 'code-name' they can enter in each questionnaire to identify participants.


### Research Plan






Cathrin Sherwood - Librarian access to journals

"What" is your intervention

Graduate attributes - know what they do/donot know (higher educaiton oeprates)

## Results

* Conclusions are clearly related to objectives of the assignment and the work shows some originality.
* You justify these in relation to past or future challenges in your practice. 
* explicitly considers the limitations of the evidence.

### Results Summary

I was unable to identify progress from september to december. The questionnaire were anonymous and students forgot the fake-names/identifies that had used in the first ones.
I have totalled the codified sentiments and discussed them below.




Missing from the audit - word skills (ment to be computing)
Complete the whole audit - IT SAYS THIS AT THE TOP - student teachers do not read

They can't all buy a domain name - THIS IS NOT FOR STUDENTS!! IT'S FOR TEACHERS/YOU

Tig

Huffman AQA only - never seen an exam question on this


### Results Discussion

before?

> The general gist is that the new audit seems to require more practical work

> I do like the emphasis on practicality, ... students often dislike even basic programming at the GCSE level, I do worry about the difficulties of showing ""students completed work to meet the learning objectives"" for many of these categories.

> I'm not sure how realistic achieving all of these areas is going to be? Do schools have 3D printers, micro-controllers, or virtual machine software preinstalled?

> is a Caesar cipher in the curriculum?

Yes; typically part of a KS2 school curriculum
https://www.cgpplus.co.uk/primary/ks2/computing/co2wat123-using-caesar-ciphers-years-5-6

> I do worry that learning some of these topics will require me to spend time away from lesson planning for the students with who I am working in order to fit these topics into my classes, which may not benefit their exam results.

> it'll be very difficult to tailor all of them to year 7s and 8s for example.
THEY ARE NOT MENT TO BE TAUGHT TO ALL 7 AND 8 STUDENTS!! THIS IS A TEACHER AUDIT!!

> the levels in the new version where better formatted so i new more about how to rate them, not just making it up myself.

> it pinpoints where one needs to improve. I'm just wondering if those areas 'will' be the ones that we need to improve on 

after?



You cant write a bubblesort (or any of these algorithms) without these concepts. There is no point in listing these lower level skills as they are implicitly required by many of the other tasks. The list of skills would also be significantly longer.

> FIND QUOTE There was no image representation or sound representation
If you can generate a sine wave, you know how to represent sound
If you can use RLE compression you know about image representation


> I think that the old audit is better, as it gives me more flexibility to work on developing my skills in ways that I see fit, as opposed to a pre-prescribed way. 
But there is no way of validating this

> I have taught some lessons that are not shown directly in the audit such as logic gates, though they may be inferred from other questions possibly.

> My confidence has increased as a result of teaching in a secondary school for three months. I am now aware that my subject knowledge is good enough to deliver classes, as opposed to pre-teaching, when I assumed that some particularly high-level students might have subject knowledge better than mine, which is far from the case in the secondary school I am currently working in

> The department management outright refused to allow me to teach according to this audit

> I haven't had time for significant work on my subject knowledge which is outside areas of the curriculum


> The school is teaching a number of things that are not in the audit.  Such as basic Word skills and other more ICT focused topics (iMedia)

> Where as the other audit was too low/easy, possibly this is setting the bar too high, more aimed at A-Level than GCSE

> Perhaps the audit could be split up into categories such as 'Computer Science Knowledge for Schools' and 'Wider Subject Knowledge' to avoid the risk of unnecessarily knocking the confidence of student teacher's subject knowledge."

> a lot of areas that have not changed as they have not been relevant to what I have been teaching.

They have been in school 8 weeks * 4 days = 32 days

> my confidence has gone up a little but I am not sure if the tracker reflects this

> I still prefer the new audit model for its clarity and easy to answer the confidence for each topic


> Several of the points on the new subject-knowledge audit are well outside of the scope of KS3, GCSEs and A Levels in Computer Science. In discussion with my department and Computing Teachers at other schools they have also agreed that there are several points that would not be covered in a Secondary School.

> it adds an unnecessary overhead of a student teacher going to learn a specific point of this tracker which whilst may be useful knowledge will not be applied to the classroom setting

> ... the new subject knowledge audit does not meet some of the topics I have made lesson. 
> For example, E-safety, Data representation (How text is stored and sound), 
> and Basic construct in programming (Sequence, Selection and Iteration)",
> Unfortunately there were no items matched

You cant write a bubblesort (or any of ther algorithums) without these concepts. There is no point in listing these lower level skills as they are implicitly required by many of the other tasks.

> It should feel like it all fits together to tick off your GCSE lesson. 

> perhaps if we don't have any evidence we could evidence a lesson we've observed and learnt something from the teacher.

Trainees did not want to actively push their skills, they wanted a tick list.

These 
Can write in sentences. Can spell words.
Can add numbers. Can 
This is a teacher knowlevel audit, not a student skill audit.
This confused trainee teachers.
One list to rule them all. Teachers have the same requirements as students. That does not sit well with me. Teachers should have more advanced knowledge than the students


> (old audit) gives me more flexibility to work on developing my skills in ways that I see fit, as opposed to a pre-prescribed way 

There was a lack of being able 

* Student teachers repeatedly misunderstood that this was a teacher knowledge/skill audit and mistakenly assumed the students needed to perform these tasks.
* Cited many times "not on the computing curriculum". Just look at the bullet points - but fail to digest/understand the opening paragraph
    * "equips pupils to use computational thinking and creativity to understand and change the world"
    * > how digital systems work and how to put this knowledge to use through programming
    * > at a level suitable for the future workplace and as active participants in a digital world
    * > can analyse problems in computational terms, and have repeated practical experience of writing computer programs in order to solve such problems
* (Peyton Jones) cited in his address - Where is the AI - we don't need to rewrite the national curriculum

Confused by "having" to do all of the audit with students. Use of GitHub - school refused.
Trainees are unable to distinguish between role requirements and knowledge requirements, curriculum

It is a mistake to proclaim/prescribe indicative content for KS3. Curriculum deliberately written to facilitate teacher freedom. Trainees lacked the experience to distinguish between 'the national curriculum' and 'their first placement school's curriculum.

What is the minimum requirement to "pass" what's on the assessment criteria. Schools make a vague attempt to define this at ks3. Mainly simplify ks4 and judge aptitude for ks4. 

Did not undertsnad level 4 - masters level discussion


Mimir - version control - convention cloud doucments are not sufficent for code (multiple files) - changes over time

* Trainee teachers and school mentors to accurately identify their current working level.
    * Mentors refused
    * Trainees agreeded reduced ambiguity - but unrelated to what they were teaching

* Provide a quantitative measure of subject knowledge progress over a 3-month period.
    * Limited

* Survey trainee’s perceived confidence of their subject knowledge development.
    * Yes
    * more ...


They don't have the time to upskill - NCCE certificates and money - importance of recruitment

Although student teachers identified that the items on the new subject knowledge audit did not fit what they were teaching in school. As each school creates their own material, I would suspect that it would be difficult for a multiple computing teachers to agree on a 'master list' of skills. The national curriculum does not provide a prescriptive list. This is to deliberately enable schools to exert autonomy over the curriculum they provide.


Research Question 1: "Can trainee teachers accurately self-evaluate their subject knowledge"
"yes" given clear enough criteria.

Research Question 2: "and use this to guide their subject knowledge development?"

The reality is "no". The driver for trainee teacher subject knowledge development is largely coupled to the trainees placement school curriculum. Anything beyond this is pragmatically optional in the eye's of a trainee. From my observations over the past 4 years of assisting PGCE trainees, their entire focus is delivering the content the school require and learning the fundamentals of how to teach. Additional subject knowledge development is not assessed and therefore not immediately required for the trainee.

### Implications and Recommendations

    * You discuss the outcomes from your evaluation and their implications for your practice across multiple domains (e.g., departmental, disciplinary, institutional and/or sector-wide implications).
    * Throughout the work you analyse relevant, detailed and specific examples from your practice in the light of educational research and theory. 
    * This reflection on your practice provides a clear vision and basis of evidence for improving your practice. 

The old subject knowledge audit provided little meaningful value because the categories were not well defined enough for a novice practitioner to identify areas of development

The new subject knowledge audit provided little meaningful value because the categories were not aligned with the institutions novice practitioners were teaching in.

My original concept, was that if teachers were able to practically demonstrate the theoretical computing concepts with practical application. This would improve the quality of lessons computing teachers were able to create. The average trainee does not have the practical skills to do this and there is not sufficient time within the course to develop these skills. In modifying to the subject knowledge audit to include a practical dimension I alienated mentors and demoralised trainees.

I wanted to show a 'complete world map' of the dimensions of the discipline of computing. Even with verbal guidance and supporting text, many of my trainees were unable to distinguish what 'could be possible over a lifetime of teaching computing' with 'what is required in the next few months to gain qualified teacher status'. They were unable to conceive the audit tool as something they might be referring to for the next 5 years+. This created confusion and stress for trainees.

The Teachers' Standards (20??) state 'Have high expectations of your learners'. I need to revisit my expectations. I feel naive for trying to make the changes that I did.

* What have you learned from doing this study?
* How can the information be useful to others?

#### Next study

If a similar study was repeated:

Biggs and Tang 2011 describe the concept of "Constructive Alignment" where the learning objectives, assessment and lesson content are all in alignment. Biggs and Tang suggest that any change to one of these must involve changes to all three components. By changing only one aspect of my course it was clear that it was going to have limited impact and create confusion. Future studies that involve alterations to course materials should be carefully consider other aspects that need to be updated.

For a more academically rigorous study, it would be wise to ensure that someone external to the project provides the codification of questionnaire responses or interviews. This will counter some the inherent bias that the creators of the study may have. Interviews should also be conducted by 3rd parties for the same reason.


#### Actions to improve practice

There is no need for a separate specialised teacher subject knowledge audit.
An exam board GCSE specification lists the knowledge/skills needed and has mechanisms for assessment/measurement.
Teachers do not have the capacity to teach topics that students are not directly assessed on.
Trainees teachers do not have the capacity to focus on developing sills for topics that students are not directly assessed on.

My subject knowledge audit enhancements focused around developing practical computing skills. The reality is that students (and therefore teachers) don't need these practical skills. The requirement for teachers is that students have the knowledge to pass the GCSE exam. Any knowledge/skills beyond a GCSE would not be standardised across a county or the country. Is up to the individual teachers or individual school computing departments to develop their own custom opportunities (if they have the capacity). These additional opportunities cannot (and maybe 'should not') be controlled by external entities.

Actions for my teaching next academic year 2022/2023:
* Replace the 'trainee teacher subject knowledge audit' with an amalgamation of current GCSE specifications from active exam boards
    * NCCE (“Computer Science Accelerator Programme”) provides a mapping tool for exam board specification to available courses
* Ask student teachers to judge their level of skill by 
    * Self administering and marking their own attempt at GCSE past papers
    * Using existing NCCE self assessment tooling. (“Diagnostic and Summative Assessment of Computing”) online tool
* Remove any reference to A-Level topics - these are beyond the scope of the course
* Direct trainee teachers towards existing skills certifications NCCE (“Computer Science Accelerator Programme”). 
    * By doing this trainee teachers accrue bursaries to take to their first employing school. This manifests externally visible and verifiable progress.

In a conversation with Tig Williams (Teacher Educator at Southampton University and Lead for the NCCE Accelerator program) in December 2021, the government £80 million funding for the NCCE is due to expire in the summer of 2022 (Sentance 2019). It will be interesting to see if the bursary support continues.


#### Next steps

Industry is taking measures into their own hands. Many employers are loosing faith in the weight behind formal computing qualifications. Industry is inventing their own professional certification and their own recruitment screening process that is largely based on practical skills. (Denning, more citation needed, this is common)

A follow-up questions might be: "What is the purpose of Computing Education in secondary schools", "What should schools be focusing on?" and "How can we make meaningful positive change to computing education?".

Speaking to undergraduates and local school teachers, there is a growing desire to develop practical computing skills that formal education is not catering for. Coder Dojo's (coderdojo.com), Coding Dojo (codingdojo.org), Code Club's (codeclub.org) and other independent groups are setting up all over the world to cater for the missing parts of computing from mainstream education. I am in the process of investigating how to provide weekly group that spans secondary students, though undergrads, though junior developers. As an institution, Canterbury Christ Church is in a great position to host such a group. It would be interesting to see if this approach is viable.




---

Notes
=====

Dont ask "why", but ask who, when (timefram), how (mehtod)
Succes/ not scucess

Aims /= methodology

Aims = raise points
Objective identify steps
Objectives == how to get to aim

Who made "comments" D2 descriptors

QA (know to do these things)
Module specifications
External examiners
Learning and teaching strategy

"What" is your intervention

Research focus need to be lifted up

Graduate attributes - know what they do/donot know (higher educaiton oeprates)


Wont destroy until grades
not shared on public platform


---


V1 - diverse
    ICT or Computing background
V2 - partcipation - differnt formats
V4 - wider context - world outside of

K5 - how do you know your teaching is effective



    * D2 - Fellow
        1. Successful incorporation of subject and pedagogic research and/or scholarship within the above activities, as part of an integrated approach to academic practice
        2. Successful engagement in continuing professional development in relation to teaching, learning, assessment and, where appropriate, related professional practices


    * Areas of Activity
        * A1
            * Design and plan learning activities and/or programmes of study
        * A2
            * Teach and/or support learning
        * A3
            * Assess and give feedback to learners
        * A4
            * Develop effective learning environments and approaches to student support and guidance
        * A5
            * Engage in continuing professional development in subjects/disciplines and their pedagogy, incorporating research, scholarship and the evaluation of professional practice
    * Core Knowledge
        * K1
            * The subject material
        * K2
            * Appropriate methods for teaching, learning and assessing in the subject area and at the level of the academic programme
        * K3
            * How students learn, both generally and within their subject/disciplinary area(s)
        * K4
            * The use and value of appropriate learning technologies
        * K5
            * Methods for evaluating the effectiveness of teaching
        * K6
            * The implications of quality assurance and quality enhancement for academic and professional practice with a particular focus on teaching
    * Professional Values
        * V1
            * Respect individual learners and diverse learning communities 
        * V2
            * Promote participation in higher education and equality of opportunity for learners
        * V3
            * Use evidence-informed approaches and the outcomes from research, scholarship and continuing professional development 
        * V4
            * Acknowledge the wider context in which higher education operates  recognising the implications for professional practice





Mark scheme
* Focus of assignment
    * Critical reflection on the D2 descriptor in relation to your own practice.

    
* Evaluation of practice
    * In the work you evaluate your practice using evidence from a range of sources and perspectives (e.g. self-reflection; student feedback; student assessment performance; observation of teaching by another educator; external examination reports). 

    

* Reflection and application to your own practice
* Engagement with scholarship and research
    * The work engages with a wide range of research and scholarship, including disciplinary pedagogies or scholarly debates within educational research. 
    * The sources cited are critically analysed and evaluated in the light of your own practice and issues implicit in the literature are made explicit and integral to the argument.
    * The work draws on scholarship from your own and other disciplines
* QWC
    * Aims
    * Logically ordered
    * Harvard
    * Figures labelled
    * proof read

Analyse the method used


The positivist paradigm is based in the assumption that a single tangible reality exists—one that can be understood, identified, and measured.

Case Study: Identify the problems.
Select the major problems in the case.
Suggest solutions to these major problems.
Recommend the best solution to be implemented.
Detail how this solution should be implemented.



* [Editorial - Developing Computationally Literate Teachers: Current Perspectives and Future Directions for Teacher Preparation in Computing Education](https://www.learntechlib.org/p/184602/)
    * Cant access



"Magic Rocks"

Interview candidate "I'm a practical person. I learn things when I need to. If I need a skill, I can learn it the night before"
"In a GCSE classroom with 30 students, you need to be able to glance at code and diagnose/debug it in around 6 to 10 seconds. This is NOT the night before"

Maybe my bar is too high
Maybe most of the things a 13 year old can tackel can be learnt by an adult 24 hours beforehand

If my mentors don't engage with this. It is meaningless to assert my opinion if I alienate the profetionals I have to work with



(Denning)
* > use competency-based skill assessments to measure student progress. Be wary of the claim of universal value, for it has little empirical support

(Nijenhuis-Voogt et al.)
* Conflicting approaches
        * "Thinking" (just the concept) or "Thinking and Making" (doing it in code)
        * > Transcribing to real code is not carried out by my students. [After writing the algorithm in pseudo-code], it does not add any value … at that time, they are at the level of understanding where they should be
        * > I want my students to be able to specify a logical solution for a problem on the level of elementary building blocks so you can make a one-on-one translation to a programming language
        * > Students will make something so they really get an idea what it involves rather than remaining theoretical


* > "What we miss in secondary education is to first think about what is needed, what is the goal, how we get there, and what steps can be distinguished."
    * > "We assess the implementation too much and I think we assess conceptual knowledge insufficiently. How do you assess whether students really understand a concept?"




[HCDA: From Computational Thinking to a Generalized Thinking Paradigm: As a new era in computing emerges, so too must our fundamental thinking patterns.](https://dl.acm.org/doi/10.1145/3418291) 2021
Argues that computation thinking alone is not enough to solve modern day problems and propose additions, we need to pair this with historical, data and archectural thinging

[Still a New Kid on the Block? Computational Thinking as Problem Solving in Code.org.](https://journals.sagepub.com/doi/10.1177/0735633120972050)
TODO


> As long as we keep designing and trying out our innovative pedagogies, we maintain the discourse on the need to change, deepen and extend our collective knowledge as to how (and how not to) improve the current situation, pushing the system to pursue a new state of equilibrium
(Kolikant)
